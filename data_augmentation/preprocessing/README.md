This directory contains the code for preprocessing the resources from DBpedia before alignment. The files are meant to be run in the following order -  

## process_abstracts
This preprocesses the abstracts from DBpedia. An important step performed here is mapping the language specific DBpedia URI to a universal URI  
   
```
python preprocess_abstracts.py --langs en --abstract_path long-abstracts_lang=en.ttl --global_ids global-ids.tsv --save_dir path/to/save
``` 
The DBpedia abstracts can be downloaded from [here](http://dev.dbpedia.org/Download_DBpedia#text) while the global-ids file can be downloaded from [here](http://dev.dbpedia.org/Download_DBpedia#id-management-and-links) 

This creates a file called ```<lang>_abstract.jsonl``` which contains data in the following format -  

```
{"resource": "http://dbpedia.org/resource/!!!", "text": "\"!!! (/tʃ(ɪ)k.tʃ(ɪ)k.tʃ(ɪ)k/ ch(i)k-ch(i)k-ch(i)k), also known as Chk Chk Chk, is an American rock band from Sacramento, California, formed in 1996 by lead singer Nic Offer. Members of !!! came from other local bands such as the Yah Mos, Black Liquorice and Pope Smashers. They are currently based in New York City. The band's ninth album, Let It Be Blue, was released in May 2022."}
```

## ontology_property_corpus  
This creates a corpus of DBpedia entities mapped to the properties which contain the entity as either the subject or the object.   
 
```
python ontology_property_corpus.py --instance_transitive_en instance-types_inference=transitive_lang=en.ttl --labels_en labels.ttl --subject_set_labels_save path/to/save --mappingbased_en mappingbased-objects_lang=en.ttl --mappingbased_literals_en mappingbased-literals_lang=en.ttl
```
The required files can be downloaded at https://databus.dbpedia.org/dbpedia/mappings and https://databus.dbpedia.org/dbpedia/wikidata.    
This saves two files. ```subject_set_labels.jsonl``` contains the labels for the entities, while ```ontology_props.jsonl``` contains the entities along with their properties   

## filter_by_category   
This filters the entities generated in the previous step according to the required domains while also merging the abstracts with entities.   

```
python filter_by_category.py --langs en --abstract_path path/to/abstract_en.jsonl  --subject_set_labels path/to/subject_set_labels.jsonl --ontology_props path/to/ontlogy_props.jsonl --instrance_transitive_en instance-types_inference=transitive_lang=en.ttl --save_name path/to/nsave  
```

This requires the files generated by the previous script and produces a new file containing the entities along with their properties and abstract text  

## translate_and_merge 
This translates the abstract text and creates a new file which contains the previous entities along with the translated text 
```
python translate_and_merge.py --langs ga --translation_save_dir path/to/save/translations --save_name path/to/save --candidates_path path/to/candidates 
````
This requires the file generated by the previous step  